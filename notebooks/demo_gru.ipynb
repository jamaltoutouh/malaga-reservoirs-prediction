{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac1fd6c5",
   "metadata": {},
   "source": [
    "# Demo: Train and evaluate a GRU predictor (PyTorch)\n",
    "This notebook contains a self-contained workflow to train a GRU model on a reservoir time series exported from InfluxDB and evaluate its forecast on a hold-out test period.\n",
    "\n",
    "It reproduces the logic implemented in `src/gru_predictor.py` but runs inside the notebook for easy experimentation and visualization.\n",
    "\n",
    "Steps:\n",
    "1. Import libraries and project utilities\n",
    "2. Load CSV (InfluxDB-style) using the shared loader\n",
    "3. Prepare sequences, scale data and create DataLoaders\n",
    "4. Define GRU model and training loop\n",
    "5. Train the model and plot training/validation loss\n",
    "6. Iterative multi-step forecasting on the test horizon\n",
    "7. Evaluate (MAE, RMSE, MAPE) and plot comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e853bb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: imports and setup\n",
    "import sys, os\n",
    "sys.path.append(os.path.abspath('../src'))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from plot_single import load_time_series, slice_by_dates\n",
    "\n",
    "print('Ready. PyTorch available:', torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902faf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Load data and prepare series\n",
    "csv_path = os.path.abspath('../data/test.csv')\n",
    "df = load_time_series(csv_path)\n",
    "print('Columns:', list(df.columns))\n",
    "\n",
    "# choose field and optional date range\n",
    "field = 'reserva'\n",
    "start = None\n",
    "end = None\n",
    "sub = slice_by_dates(df, start, end)\n",
    "series = pd.to_numeric(sub[field], errors='coerce')\n",
    "series.index = sub.index\n",
    "series = series.dropna()\n",
    "print('Series length:', len(series), 'from', series.index.min(), 'to', series.index.max())\n",
    "\n",
    "# hyperparameters for demo\n",
    "test_days = 30\n",
    "seq_len = 30\n",
    "hidden_size = 64\n",
    "num_layers = 1\n",
    "epochs = 30\n",
    "batch_size = 32\n",
    "lr = 1e-3\n",
    "\n",
    "train = series.iloc[:-test_days]\n",
    "test = series.iloc[-test_days:]\n",
    "\n",
    "# scaling\n",
    "scaler = StandardScaler()\n",
    "train_vals = train.values.reshape(-1, 1)\n",
    "scaler.fit(train_vals)\n",
    "all_scaled = scaler.transform(series.values.reshape(-1, 1)).ravel()\n",
    "train_scaled = scaler.transform(train.values.reshape(-1,1)).ravel()\n",
    "\n",
    "# helper to create sequences\n",
    "def create_sequences(values, seq_len):\n",
    "    X, y = [], []\n",
    "    for i in range(len(values) - seq_len):\n",
    "        X.append(values[i:i+seq_len])\n",
    "        y.append(values[i+seq_len])\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    if X.ndim == 2:\n",
    "        X = X.reshape(X.shape[0], X.shape[1], 1)\n",
    "    return X, y\n",
    "\n",
    "X_all, y_all = create_sequences(all_scaled[:len(train_scaled)], seq_len)\n",
    "# validation split\n",
    "n_train = int(len(X_all) * 0.9)\n",
    "X_train, y_train = X_all[:n_train], y_all[:n_train]\n",
    "X_val, y_val = X_all[n_train:], y_all[n_train:]\n",
    "\n",
    "print('Train samples:', len(X_train), 'Val samples:', len(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5486d6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Dataset, model and training functions\n",
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, seqs, targets):\n",
    "        self.x = seqs.astype(np.float32)\n",
    "        self.y = targets.astype(np.float32)\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]\n",
    "\n",
    "class GRUModel(nn.Module):\n",
    "    def __init__(self, input_size=1, hidden_size=64, num_layers=1, dropout=0.0):\n",
    "        super().__init__()\n",
    "        self.gru = nn.GRU(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True, dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "    def forward(self, x):\n",
    "        out, _ = self.gru(x)\n",
    "        out = out[:, -1, :]\n",
    "        out = self.fc(out)\n",
    "        return out.squeeze(-1)\n",
    "\n",
    "# training loop returning history\n",
    "def train_model(model, train_loader, val_loader, device, epochs=20, lr=1e-3):\n",
    "    model.to(device)\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    loss_fn = nn.MSELoss()\n",
    "    best_val = np.inf\n",
    "    best_state = None\n",
    "    history = {'train_loss': [], 'val_loss': []}\n",
    "    for ep in range(1, epochs+1):\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        for xb, yb in train_loader:\n",
    "            xb = xb.to(device); yb = yb.to(device)\n",
    "            pred = model(xb)\n",
    "            loss = loss_fn(pred, yb)\n",
    "            opt.zero_grad(); loss.backward(); opt.step()\n",
    "            train_losses.append(loss.item())\n",
    "        model.eval()\n",
    "        val_losses = []\n",
    "        with torch.no_grad():\n",
    "            for xb, yb in val_loader:\n",
    "                xb = xb.to(device); yb = yb.to(device)\n",
    "                pred = model(xb)\n",
    "                val_losses.append(float(loss_fn(pred, yb)))\n",
    "        tloss = np.mean(train_losses) if train_losses else np.nan\n",
    "        vloss = np.mean(val_losses) if val_losses else np.nan\n",
    "        history['train_loss'].append(tloss); history['val_loss'].append(vloss)\n",
    "        print(f'Epoch {ep}/{epochs} train_loss={tloss:.6f} val_loss={vloss:.6f}')\n",
    "        if vloss < best_val:\n",
    "            best_val = vloss; best_state = model.state_dict()\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "    return model, history\n",
    "\n",
    "# iterative forecasting function\n",
    "def iterative_forecast(model, seed_seq, steps, device, scaler=None):\n",
    "    model.to(device); model.eval()\n",
    "    seq = seed_seq.copy().astype(np.float32)\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for _ in range(steps):\n",
    "            x = torch.tensor(seq.reshape(1, seq.shape[0], 1), dtype=torch.float32).to(device)\n",
    "            out = model(x).cpu().numpy().ravel()[0]\n",
    "            preds.append(out)\n",
    "            seq = np.roll(seq, -1); seq[-1] = out\n",
    "    preds = np.array(preds)\n",
    "    if scaler is not None:\n",
    "        preds = scaler.inverse_transform(preds.reshape(-1,1)).ravel()\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7693c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Prepare DataLoaders, build model and train\n",
    "train_ds = TimeSeriesDataset(X_train, y_train)\n",
    "val_ds = TimeSeriesDataset(X_val, y_val)\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Device:', device)\n",
    "\n",
    "model = GRUModel(input_size=1, hidden_size=hidden_size, num_layers=num_layers)\n",
    "model, history = train_model(model, train_loader, val_loader, device, epochs=epochs, lr=lr)\n",
    "\n",
    "# plot loss\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(history['train_loss'], label='train')\n",
    "plt.plot(history['val_loss'], label='val')\n",
    "plt.xlabel('Epoch'); plt.ylabel('MSE'); plt.legend(); plt.title('Training loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870e69cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Forecast and evaluate on test horizon\n",
    "seed_start = len(series) - test_days - seq_len\n",
    "seed_seq = all_scaled[seed_start:seed_start+seq_len]\n",
    "preds = iterative_forecast(model, seed_seq, steps=test_days, device=device, scaler=scaler)\n",
    "\n",
    "true = test.values\n",
    "mae = np.mean(np.abs(true - preds))\n",
    "rmse = np.sqrt(np.mean((true - preds)**2))\n",
    "mape = np.mean(np.abs((true - preds)/np.where(true==0, np.nan, true))) * 100\n",
    "print(f'GRU MAE={mae:.4f} RMSE={rmse:.4f} MAPE={mape:.2f}%')\n",
    "\n",
    "pred_series = pd.Series(preds, index=test.index)\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(train.index, train.values, color='gray', label='train')\n",
    "plt.plot(test.index, test.values, color='black', label='test')\n",
    "plt.plot(pred_series.index, pred_series.values, color='tab:blue', label='GRU')\n",
    "plt.legend(); plt.title('GRU forecast vs test')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
